\documentclass[../main.tex]{subfiles}
\begin{document}
\chapter{Implementation}
\section{The Technology Stack}
\subsection{The Language Server}
Before any work could be done, I needed to decide on which technology stack to use. This was dictated mainly by the programming language involved. The following features were needed:
\\
\\
\textbf{Linux, Windows and Mac OS support} \\
The language server had to be able to connect to offline editors, and therefore run on user's desktops. This meant that the most up-to-date editions of the three most popular operating systems -- Linux, Windows and Mac OS X -- had to be supported.
\\
\\
\textbf{Support for strong typing} \\
Since creating a language server is a large and complex project, I needed to be using a langauge with strong typing in order to both avoid mistakes and receive context-aware support from my IDE.
\\
\\
\textbf{A Language Server Protocol API} \\
Writing Language Server Protocol requests manually would be inefficient, time-consuming and a potential cause of errors. A library that abstracted away the exact layout and content of Language Server Protocol requests would aid productivity.
\\ 
\\
These last two requirements only left two libraries: the \\ 
\texttt{Microsoft.VisualStudio.LanguageServer}, written for C\# \cite{visual_studio_language_server}, or \\ 
\texttt{vscode-languageserver}, written for TypeScript \cite{vsc_langserver_docs}. Since these libraries are were created by Microsoft \footnote{This should not be surprising, as Microsoft also created the Language Server Protocol.}, they are structured quite similarly. 
\\
\\
In the end, the TypeScript library was chosen over the C\# library. Both libraries being quite similar, this decision was made because TypeScript was better suited for the task than C\#. The Language Server Protocol communicates using JSON, and TypeScript can handle JSON more fluidly than C\# can. Useful features include destructuring JSON, giving JSON objects unique types based on their fields, and treating JSON objects as implementing interfaces that have the same fields. This decision being made, the resulting technology stack was TypeScript run locally using \codeword{Node.JS}. 

\subsection{The Syntax Highlighter}
Since the syntax highlighting is specified in a single JSON document, the technology stack required was minimal. Rather than writing the JSON document directly, I chose to write the TextMate grammar in a YAML document, from which the JSON document was then automatically generated using the command \codeword{yq} \cite{yq_repo}. This was done because of the length of the JSON required: YAML documents are easier to read due to their less cluttered syntax, with the scope of objects being determined by whitespace rather than brackets. Writing regular expressions is also easier in a YAML document. Regular expressions feature many backslashes: in JSON, unlike in YAML, these backslashes need to be escaped with another backslash. Regular expressions are confusing enough to read as they are -- I did not need any added confusion by having to parse escaped backslashes in my head!

\subsection{The Language Client}
Language servers written using the \texttt{vscode-languageserver} library connect seamlessly to visual studio code language clients written using the \texttt{vscode-languageclient} package. Thus, my main method of day-to-day testing was done using a local visual studio code client. I could be assured that all errors I found were due to the language server itself, not the connection, since the two libraries were built with each other in mind. Tests were also done using a Codemirror 5 client that ran locally in the browser, to see which features carried over to Codemirror 5.



\section{The Syntax Highlighter}
Using TextMate grammar, the syntax highlighter identified three tiers of Logical English features.

\subsection{Sub-Line Features}
The syntax highlighter marks keywords that are contained within a single line, such as \codeword{if}, \codeword{and}, \codeword{or}, \codeword{it is the case that} and \codeword{it is not the case that}. It also marks the pre-defined constant term \codeword{unknown}. This is done simply by recognising these keywords wherever they appear and are surrounded by word boundaries (i.e. spaces, tabs or other non-word characters). 
\\ 
\\ 
A proposed feature is for the language extension to allow for such keywords to appear in template names, where they would have to be marked differently. This would not be a problem: the language server can override the syntax highlighter in its semantic highlighting.
\\ 
\\ 
The syntax highlighter also marks single-line comments that begin with \codeword{\%} and span until the end of the line. However, all the syntax highlighter does is mark them: it is a separate feature of the language server to ignore comments.

\subsection{Single-Line features}
The syntax highlighter also marks the headers of sections of a Logical English document. For the template section header, \codeword{the templates are:}, the characters from the initial \codeword{t} up to the final \codeword{e} is marked as a single header block. Beginning at the initial word character is an important point, since Logical English allows headers to be indented. 
\\ 
\\\
The knowledge base, scenario and query headers all support being named. Thus, their names are marked separately from the rest of the header. 
\\ 
\\
It is interesting to note what TextMate grammar identifiers are used to mark the headers. Following the TextMate naming conventions \cite{textmate_grammars_spec} is essential to maximise the amount of colour schemes that colour Logical English documents correctly. However, the guidelines are quite vague, with \codeword{entity}, \codeword{meta} and \codeword{markup.heading} all being recommended for use in marking up section headers. 
\\ 
\\
The most pragmatic course of action was to survey a variety of popular TextMate grammars. Finding analogies of section headers in popular languages was difficult. In C-style languages, sections of code are either labelled with single-word keywords such as \codeword{if}, \codeword{for} or \codeword{while}, or also name a type of data structure, such as class or interface names. These are semantically quite different from Logical English section headers. In the end, I settled on a function name, used in a function definition or declaration, as being the closest analogy. Although the function name may reappear in the document, it does not represent a type and rarely represents data (the data instead usually being the return value, at the end of a function call). This was usually labelled with \codeword{entity.name} prefix. The fact that the names of HTML tags are also labelled with \codeword{entity.name} was further evidence that \codeword{entity.name} was the best choice. 
\todo[inline]{Put some references to popular IDE's default TextMate schemes here. Also maybe talk about why the name of a query / section / knowledge base is given variable.}


\section{The Language Server}
The language server is a complex tool and has multiple features. Each category of feature corresponds, in the most part, been extracted into a single source code file. 


\subsection{Design choices}
\todo[inline]{Research design methodologies, cite which methodology corresponds to mine.}
In parsing a Logical English document, the language server is heavily reliant on ``helper functions". A common class of problem is, given a pattern or structure, to extract parts of a block of code according to the pattern. For instance, is done in (but is not limited to):
\begin{itemize}
    \item extracting the template section or knowledge base section from the document
    \item extracting clauses from the knowledge base section, and templates from the template section
    \item extracting literals from clauses
    \item extracting terms from a literal, assuming that a literal matches a given template
\end{itemize}
These core functionalities are used throughout the language server. 


\subsection{Connection to a Language Client}
\todo[inline]{Research more about how this works.}


\subsection{Semantic Highlighting}
The language server understands the semantics of a logical english document in highlighting the terms that appear in literals. Mere syntactic highlighting is not powerful enough to do this. The structure of each literal, and the template that it corresponds to, has to be understood in order for this to take place.
\\ 
\\

\subsection{Code Completion}

\subsection{Error Diagnostics}

\subsection{Error Fixes}

\section{The Visual Studio Code Language Client}

\end{document}
